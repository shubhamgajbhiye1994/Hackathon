{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metalgradeclassificationmodel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8guAP7J45Bf",
        "colab_type": "text"
      },
      "source": [
        "Problem Statemnet and its Deatils :\n",
        "Manufacturing of any alloy is not a simple process. Many complicated factors are involved in the making of a perfect alloy, from the temperature at which various metals are melted to the presence of impurities to the cooling temperature set to cool down the alloy. Very minor changes in any of these factors can affect the quality or grade of the alloy produced.\n",
        "\n",
        "Given are 28 distinguishing factors in the manufacturing of an alloy, your objective as a data scientist is to build a Machine Learning model that can predict the grade of the product using these factors.\n",
        "\n",
        "You are provided with 28 anonymized factors (f0 to f27) that influence the making of a perfect alloy that is to be used for various applications based on the grade/quality of the obtained product.\n",
        "Data Description\n",
        "\n",
        "The unzipped folder will have the following files.\n",
        "\n",
        "    Train.csv – 620 observations.\n",
        "    Test.csv – 266 observations.\n",
        "    Sample Submission – Sample format for the submission.\n",
        "\n",
        "Target Variable: \n",
        "\n",
        "Socre = log loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "492OM130txqp",
        "colab_type": "text"
      },
      "source": [
        "Note : This is version 2 program of xgboost which used for hackathon which help me to get in top 3% participation.\n",
        "- Outlier handling is not done (need domain knowledge for this) you can do this by using various tech."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfIdoWfN1ig7",
        "colab_type": "code",
        "outputId": "4f20e353-641b-44ae-dd84-81f75e0c3199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "#mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7GXAdED2E86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#chnage the current directory to working directory\n",
        "\n",
        "import os \n",
        "os.chdir(\"/content/gdrive/My Drive/Hackathon/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y97vmIm52U7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzip files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('MetalFurnace-Participants_Data.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNhsNVX42rPc",
        "colab_type": "code",
        "outputId": "7976c42a-ea95-4a1b-a6b9-604d1063e9a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "#importing lib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2jDbLZR2_gG",
        "colab_type": "code",
        "outputId": "c92a6106-1b67-40d7-96e2-7569191002db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "#lets read dataset and get deep drive into dataset\n",
        "\n",
        "train_df = pd.read_csv(\"MetalFurnace-Participants_Data/Train.csv\")\n",
        "train_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f0</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.848564</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>1.305455</td>\n",
              "      <td>2.329398</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.548623</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>-1.080663</td>\n",
              "      <td>0.443257</td>\n",
              "      <td>-0.406121</td>\n",
              "      <td>-0.687687</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>3.727218</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.825098</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>3.032397</td>\n",
              "      <td>-2.442599</td>\n",
              "      <td>1.305455</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.548623</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>-1.080663</td>\n",
              "      <td>-0.232546</td>\n",
              "      <td>-0.406366</td>\n",
              "      <td>-0.687687</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.848564</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>1.305455</td>\n",
              "      <td>2.329398</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.548623</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>0.925358</td>\n",
              "      <td>1.459782</td>\n",
              "      <td>1.221876</td>\n",
              "      <td>1.877777</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.511733</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>-0.525726</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>-1.999287</td>\n",
              "      <td>-2.118189</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>-3.237512</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>0.925358</td>\n",
              "      <td>-0.008030</td>\n",
              "      <td>-0.406366</td>\n",
              "      <td>1.504523</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.825098</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>-0.525726</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.526055</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>-1.999287</td>\n",
              "      <td>-2.118189</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>0.925358</td>\n",
              "      <td>-0.573268</td>\n",
              "      <td>-1.164793</td>\n",
              "      <td>1.877777</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.825098</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>1.305455</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>-2.695676</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>-1.999287</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>-1.080663</td>\n",
              "      <td>0.443257</td>\n",
              "      <td>1.087230</td>\n",
              "      <td>-0.687687</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.825098</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>-0.525726</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>-2.695676</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.548623</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>0.925358</td>\n",
              "      <td>-0.233674</td>\n",
              "      <td>1.332042</td>\n",
              "      <td>1.877777</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.511733</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>-0.525726</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>-1.999287</td>\n",
              "      <td>-2.118189</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>0.925358</td>\n",
              "      <td>-0.910605</td>\n",
              "      <td>-0.406121</td>\n",
              "      <td>-0.608830</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.379487</td>\n",
              "      <td>4.550071</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>1.305455</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>-0.725332</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>-1.080663</td>\n",
              "      <td>1.233010</td>\n",
              "      <td>-0.332678</td>\n",
              "      <td>-0.687687</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>3.727218</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.066123</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>1.305455</td>\n",
              "      <td>2.665597</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>-3.237512</td>\n",
              "      <td>-0.725332</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>-1.080663</td>\n",
              "      <td>0.443257</td>\n",
              "      <td>-0.406121</td>\n",
              "      <td>-0.687687</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         f0        f1        f2        f3  ...       f25       f26       f27  grade\n",
              "0  1.848564 -0.264250 -0.461423  0.409400  ...  0.271886  3.727218  0.102129      2\n",
              "1 -0.825098 -0.264250  3.032397 -2.442599  ...  0.271886 -0.232472  0.102129      4\n",
              "2  1.848564 -0.264250 -0.461423  0.409400  ...  0.271886 -0.232472  0.102129      2\n",
              "3  0.511733 -0.264250 -0.461423  0.409400  ...  0.271886 -0.232472  0.102129      2\n",
              "4 -0.825098 -0.264250 -0.461423  0.409400  ...  0.271886 -0.232472  0.102129      2\n",
              "5 -0.825098 -0.264250 -0.461423  0.409400  ...  0.271886 -0.232472  0.102129      3\n",
              "6 -0.825098 -0.264250 -0.461423  0.409400  ...  0.271886 -0.232472  0.102129      2\n",
              "7  0.511733 -0.264250 -0.461423  0.409400  ...  0.271886 -0.232472  0.102129      2\n",
              "8 -0.379487  4.550071 -0.461423  0.409400  ...  0.271886  3.727218  0.102129      2\n",
              "9  0.066123 -0.264250 -0.461423  0.409400  ...  0.271886 -0.232472  0.102129      2\n",
              "\n",
              "[10 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZVH6F6J3tVw",
        "colab_type": "text"
      },
      "source": [
        "Here you can see that there are about 27 independet variables i.e from f0 to f27 and target variable grade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqoNPpCn38Cr",
        "colab_type": "code",
        "outputId": "ee8da0ed-ef41-47e3-9d19-5a7fd2deb65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        }
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 620 entries, 0 to 619\n",
            "Data columns (total 29 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   f0      620 non-null    float64\n",
            " 1   f1      620 non-null    float64\n",
            " 2   f2      620 non-null    float64\n",
            " 3   f3      620 non-null    float64\n",
            " 4   f4      620 non-null    float64\n",
            " 5   f5      620 non-null    float64\n",
            " 6   f6      620 non-null    float64\n",
            " 7   f7      620 non-null    float64\n",
            " 8   f8      620 non-null    float64\n",
            " 9   f9      620 non-null    float64\n",
            " 10  f10     620 non-null    float64\n",
            " 11  f11     620 non-null    float64\n",
            " 12  f12     620 non-null    float64\n",
            " 13  f13     620 non-null    float64\n",
            " 14  f14     620 non-null    float64\n",
            " 15  f15     620 non-null    float64\n",
            " 16  f16     620 non-null    float64\n",
            " 17  f17     620 non-null    float64\n",
            " 18  f18     620 non-null    float64\n",
            " 19  f19     620 non-null    float64\n",
            " 20  f20     620 non-null    float64\n",
            " 21  f21     620 non-null    float64\n",
            " 22  f22     620 non-null    float64\n",
            " 23  f23     620 non-null    float64\n",
            " 24  f24     620 non-null    float64\n",
            " 25  f25     620 non-null    float64\n",
            " 26  f26     620 non-null    float64\n",
            " 27  f27     620 non-null    float64\n",
            " 28  grade   620 non-null    int64  \n",
            "dtypes: float64(28), int64(1)\n",
            "memory usage: 140.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEE4kDs_3-1h",
        "colab_type": "code",
        "outputId": "ab6b30fc-ebc5-42fa-a855-ad4aa72c20a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        }
      },
      "source": [
        "train_df.describe().T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>f0</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-1.344802e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-0.825098</td>\n",
              "      <td>-0.825098</td>\n",
              "      <td>-0.379487</td>\n",
              "      <td>0.511733</td>\n",
              "      <td>2.294174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1</th>\n",
              "      <td>620.0</td>\n",
              "      <td>6.596874e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>-0.264250</td>\n",
              "      <td>4.920404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f2</th>\n",
              "      <td>620.0</td>\n",
              "      <td>3.697759e-17</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>-0.461423</td>\n",
              "      <td>3.032397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f3</th>\n",
              "      <td>620.0</td>\n",
              "      <td>6.503758e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-2.442599</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>0.409400</td>\n",
              "      <td>0.409400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f4</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-9.454803e-17</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-2.356907</td>\n",
              "      <td>-0.525726</td>\n",
              "      <td>-0.525726</td>\n",
              "      <td>1.305455</td>\n",
              "      <td>1.305455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f5</th>\n",
              "      <td>620.0</td>\n",
              "      <td>1.146037e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>-0.276144</td>\n",
              "      <td>5.607339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f6</th>\n",
              "      <td>620.0</td>\n",
              "      <td>1.577591e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-2.695676</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.370965</td>\n",
              "      <td>0.370965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f7</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-2.734820e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-11.090537</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.090167</td>\n",
              "      <td>0.090167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f8</th>\n",
              "      <td>620.0</td>\n",
              "      <td>6.083843e-17</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-13.278881</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.107958</td>\n",
              "      <td>0.107958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f9</th>\n",
              "      <td>620.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f10</th>\n",
              "      <td>620.0</td>\n",
              "      <td>2.494420e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-2.526055</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.395874</td>\n",
              "      <td>0.395874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f11</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-2.829278e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-3.237512</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.308879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f12</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-8.899691e-17</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-1.999287</td>\n",
              "      <td>0.548623</td>\n",
              "      <td>0.548623</td>\n",
              "      <td>0.548623</td>\n",
              "      <td>0.548623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f13</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-1.197966e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-2.118189</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.472101</td>\n",
              "      <td>0.472101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f14</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-2.104052e-17</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-5.783117</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.172917</td>\n",
              "      <td>0.172917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f15</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-8.366963e-17</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-10.115994</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.098853</td>\n",
              "      <td>0.098853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f16</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-2.652000e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-3.237512</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.308879</td>\n",
              "      <td>0.308879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f17</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-3.377674e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-24.879711</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.040193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f18</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-3.220542e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-5.477226</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.182574</td>\n",
              "      <td>0.182574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f19</th>\n",
              "      <td>620.0</td>\n",
              "      <td>1.148947e-15</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-13.167792</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.085505</td>\n",
              "      <td>0.085505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f20</th>\n",
              "      <td>620.0</td>\n",
              "      <td>1.893647e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-4.286607</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>0.233285</td>\n",
              "      <td>0.233285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f21</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-1.633102e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-1.080663</td>\n",
              "      <td>-1.080663</td>\n",
              "      <td>0.925358</td>\n",
              "      <td>0.925358</td>\n",
              "      <td>0.925358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f22</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-9.383175e-17</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-1.079838</td>\n",
              "      <td>-0.683833</td>\n",
              "      <td>-0.459318</td>\n",
              "      <td>0.443257</td>\n",
              "      <td>3.150982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f23</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-4.297638e-18</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-1.899472</td>\n",
              "      <td>-0.406366</td>\n",
              "      <td>-0.406121</td>\n",
              "      <td>1.160673</td>\n",
              "      <td>1.833906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f24</th>\n",
              "      <td>620.0</td>\n",
              "      <td>2.087936e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-0.687687</td>\n",
              "      <td>-0.687687</td>\n",
              "      <td>-0.365953</td>\n",
              "      <td>-0.287096</td>\n",
              "      <td>1.877777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f25</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-2.721837e-17</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-4.914855</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>0.271886</td>\n",
              "      <td>0.271886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f26</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-2.615291e-16</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>-0.232472</td>\n",
              "      <td>4.519156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f27</th>\n",
              "      <td>620.0</td>\n",
              "      <td>-1.763822e-17</td>\n",
              "      <td>1.000807</td>\n",
              "      <td>-15.727802</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>0.102129</td>\n",
              "      <td>0.102129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grade</th>\n",
              "      <td>620.0</td>\n",
              "      <td>2.033871e+00</td>\n",
              "      <td>0.630779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       count          mean       std  ...       50%       75%       max\n",
              "f0     620.0 -1.344802e-16  1.000807  ... -0.379487  0.511733  2.294174\n",
              "f1     620.0  6.596874e-16  1.000807  ... -0.264250 -0.264250  4.920404\n",
              "f2     620.0  3.697759e-17  1.000807  ... -0.461423 -0.461423  3.032397\n",
              "f3     620.0  6.503758e-16  1.000807  ...  0.409400  0.409400  0.409400\n",
              "f4     620.0 -9.454803e-17  1.000807  ... -0.525726  1.305455  1.305455\n",
              "f5     620.0  1.146037e-16  1.000807  ... -0.276144 -0.276144  5.607339\n",
              "f6     620.0  1.577591e-16  1.000807  ...  0.370965  0.370965  0.370965\n",
              "f7     620.0 -2.734820e-16  1.000807  ...  0.090167  0.090167  0.090167\n",
              "f8     620.0  6.083843e-17  1.000807  ...  0.107958  0.107958  0.107958\n",
              "f9     620.0  0.000000e+00  0.000000  ...  0.000000  0.000000  0.000000\n",
              "f10    620.0  2.494420e-16  1.000807  ...  0.395874  0.395874  0.395874\n",
              "f11    620.0 -2.829278e-16  1.000807  ...  0.308879  0.308879  0.308879\n",
              "f12    620.0 -8.899691e-17  1.000807  ...  0.548623  0.548623  0.548623\n",
              "f13    620.0 -1.197966e-16  1.000807  ...  0.472101  0.472101  0.472101\n",
              "f14    620.0 -2.104052e-17  1.000807  ...  0.172917  0.172917  0.172917\n",
              "f15    620.0 -8.366963e-17  1.000807  ...  0.098853  0.098853  0.098853\n",
              "f16    620.0 -2.652000e-16  1.000807  ...  0.308879  0.308879  0.308879\n",
              "f17    620.0 -3.377674e-16  1.000807  ...  0.040193  0.040193  0.040193\n",
              "f18    620.0 -3.220542e-16  1.000807  ...  0.182574  0.182574  0.182574\n",
              "f19    620.0  1.148947e-15  1.000807  ...  0.085505  0.085505  0.085505\n",
              "f20    620.0  1.893647e-16  1.000807  ...  0.233285  0.233285  0.233285\n",
              "f21    620.0 -1.633102e-16  1.000807  ...  0.925358  0.925358  0.925358\n",
              "f22    620.0 -9.383175e-17  1.000807  ... -0.459318  0.443257  3.150982\n",
              "f23    620.0 -4.297638e-18  1.000807  ... -0.406121  1.160673  1.833906\n",
              "f24    620.0  2.087936e-16  1.000807  ... -0.365953 -0.287096  1.877777\n",
              "f25    620.0 -2.721837e-17  1.000807  ...  0.271886  0.271886  0.271886\n",
              "f26    620.0 -2.615291e-16  1.000807  ... -0.232472 -0.232472  4.519156\n",
              "f27    620.0 -1.763822e-17  1.000807  ...  0.102129  0.102129  0.102129\n",
              "grade  620.0  2.033871e+00  0.630779  ...  2.000000  2.000000  4.000000\n",
              "\n",
              "[29 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYu6bTpc4OTv",
        "colab_type": "text"
      },
      "source": [
        "Target variable has 0 to 4 different values i.e. total 5 different values , so it means that we need to predict the class.\n",
        "f0 to f27 are the variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcLHRyB34ICG",
        "colab_type": "code",
        "outputId": "650a3c1a-2eb1-4217-bb65-6cb1ffe17c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "#lets whether data has some null values or not\n",
        "\n",
        "train_df.isnull().any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "f0       False\n",
              "f1       False\n",
              "f2       False\n",
              "f3       False\n",
              "f4       False\n",
              "f5       False\n",
              "f6       False\n",
              "f7       False\n",
              "f8       False\n",
              "f9       False\n",
              "f10      False\n",
              "f11      False\n",
              "f12      False\n",
              "f13      False\n",
              "f14      False\n",
              "f15      False\n",
              "f16      False\n",
              "f17      False\n",
              "f18      False\n",
              "f19      False\n",
              "f20      False\n",
              "f21      False\n",
              "f22      False\n",
              "f23      False\n",
              "f24      False\n",
              "f25      False\n",
              "f26      False\n",
              "f27      False\n",
              "grade    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmytvN1A5ctb",
        "colab_type": "code",
        "outputId": "4f04e729-d413-4068-8e61-41a5b0a2c335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "#lets check the target variable distribution in dataset\n",
        "train_df.grade.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    472\n",
              "1     68\n",
              "3     47\n",
              "4     27\n",
              "0      6\n",
              "Name: grade, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4c6Mu5h53sf",
        "colab_type": "text"
      },
      "source": [
        "You can see that grade 0 has least no of records and grade 2 has max no of records , so we need to upscale the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICRRRfiA5p7q",
        "colab_type": "code",
        "outputId": "97702468-28ab-42c6-e48d-0cffbd4658b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "#lets do dimension reduction , normalization and upscaling\n",
        "\n",
        "pca = PCA()\n",
        "scale = StandardScaler()\n",
        "sm = SMOTE()\n",
        "\n",
        "x = train_df.drop(columns='grade')\n",
        "y = train_df.grade\n",
        "x1 , y1 = sm.fit_resample(x,y)\n",
        "x_scale = scale.fit_transform(x1)\n",
        "x_pca = pca.fit_transform(x_scale)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUYtmQ6IbEO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#defining tunning parameter\n",
        "params = {\n",
        "    'learning_rate' : [0.1,0.001,0.01],\n",
        "    'max_depth': [3,5,7,11],\n",
        "    'min_child_weight' : [1,2,3,5],\n",
        "    'lamdba':[0.5,1,2,0.2,0.3],\n",
        "    'gamma':[0.1,0.2,0.3],\n",
        "    'scale_pos_weight' : [1,3,2,0.5],\n",
        "    'objective':'multi:softmax',\n",
        "    'num_class': [4],\n",
        "    'subsample':[0.5,1],\n",
        "    'n_estimators':[1000],\n",
        "    'early_stopping_rounds':[2],\n",
        "    'colsample_bytree':[0.5,0.6,0.7,0.8,0.9 ],\n",
        "    'num_boost_round' :[999]\n",
        "}\n",
        "\n",
        "\n",
        "#defining model\n",
        "classifier = xgb.XGBClassifier()\n",
        "\n",
        "#cross calidation fold for data validation \n",
        "stf = StratifiedKFold(n_splits=5,shuffle=True,random_state=123)\n",
        "\n",
        "#parameter tunning algo\n",
        "random = RandomizedSearchCV(estimator=classifier,param_distributions=params,n_iter=50,scoring='neg_log_loss',cv=stf,verbose=1,n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Q-brxBbLsZ",
        "colab_type": "code",
        "outputId": "9be1c6d7-ef6e-4aba-81a1-2ce7e47955fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "#fitting model\n",
        "\n",
        "random.fit(x_pca,y1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 38.8min\n",
            "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 48.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
              "                   error_score=nan,\n",
              "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                           colsample_bylevel=1,\n",
              "                                           colsample_bynode=1,\n",
              "                                           colsample_bytree=1, gamma=0,\n",
              "                                           learning_rate=0.1, max_delta_step=0,\n",
              "                                           max_depth=3, min_child_weight=1,\n",
              "                                           missing=None, n_estimators=100,\n",
              "                                           n_jobs=1, nthread=None,\n",
              "                                           objective='bin...\n",
              "                                        'lamdba': [0.5, 1, 2, 0.2, 0.3],\n",
              "                                        'learning_rate': [0.1, 0.001, 0.01],\n",
              "                                        'max_depth': [3, 5, 7, 11],\n",
              "                                        'min_child_weight': [1, 2, 3, 5],\n",
              "                                        'n_estimators': [1000],\n",
              "                                        'num_boost_round': [999],\n",
              "                                        'num_class': [4],\n",
              "                                        'objective': 'multi:softmax',\n",
              "                                        'scale_pos_weight': [1, 3, 2, 0.5],\n",
              "                                        'subsample': [0.5, 1]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='neg_log_loss', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c677lGkLrq4B",
        "colab_type": "code",
        "outputId": "8385ee95-e7f3-41f7-b099-6c2427eb757b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#save the model\n",
        "\n",
        "from joblib import load,dump\n",
        "dump(random,'MetalFurnace-Participants_Data/xgb_alloygrad_model_v2.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MetalFurnace-Participants_Data/xgb_alloygrad_model_v2.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrYgyJRZdtm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets read the test file and predict the probabilities and save the result into file\n",
        "\n",
        "#read file\n",
        "test_df = pd.read_csv(\"MetalFurnace-Participants_Data/Test.csv\")\n",
        "\n",
        "#transforming data as look like train data\n",
        "test = pca.transform(scale.transform(test_df))\n",
        "\n",
        "#predicting the probabilities\n",
        "y_predicted = random.predict_proba(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXOODwtz5fXS",
        "colab_type": "code",
        "outputId": "ab0da0fc-c7a0-4599-9020-9948c9531c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "y_predicted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.2438282e-06, 5.8877034e-05, 9.9983251e-01, 2.3628301e-05,\n",
              "        7.6711294e-05],\n",
              "       [3.4080411e-05, 1.7166214e-05, 2.9953071e-03, 9.9685127e-01,\n",
              "        1.0220550e-04],\n",
              "       [1.3025860e-04, 2.4466046e-05, 9.9902856e-01, 2.0629482e-04,\n",
              "        6.1044551e-04],\n",
              "       ...,\n",
              "       [7.4440596e-04, 9.7977640e-03, 9.8753637e-01, 1.0246943e-03,\n",
              "        8.9677057e-04],\n",
              "       [4.9194685e-05, 9.2813370e-06, 9.9963617e-01, 2.2498869e-04,\n",
              "        8.0387690e-05],\n",
              "       [2.6538188e-04, 4.6853069e-04, 9.9780506e-01, 7.8210572e-04,\n",
              "        6.7889626e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugJQhq2IjUGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_result = pd.DataFrame(data=y_predicted,columns=[0,1,2,3,4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9JxgiKLjWqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_result.to_csv('MetalFurnace-Participants_Data/final_submission_xgb_V2.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}